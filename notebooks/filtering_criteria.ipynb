{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b9d42-2836-4bb9-96d1-750101b62b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contain_numbers(phrase):\n",
    "    return bool(re.search(r'\\d', phrase))\n",
    "\n",
    "sample = {'category': 'HISTORY', 'air_date': '2004-12-31', 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\", 'value': '$200', 'answer': 'Copernicus', 'round': 'Jeopardy!', 'show_number': '4680'}\n",
    "print (contain_numbers(sample['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc17b8-3b40-4d3b-bf20-c339b30060aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words, names\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "nltk.download('words')\n",
    "nltk.download('names')\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def contain_non_english(phrase):\n",
    "    english_words = set(words.words())\n",
    "    english_names = set(names.words())\n",
    "    \n",
    "    tokens = word_tokenize(phrase)\n",
    "    \n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    named_entities = set()\n",
    "    \n",
    "    for chunk in ne_chunk(tagged_tokens):\n",
    "        if isinstance(chunk, Tree): \n",
    "            named_entity = \" \".join(c[0] for c in chunk)\n",
    "            named_entities.add(named_entity.lower())\n",
    "\n",
    "    non_english = [\n",
    "        word for word in tokens \n",
    "        if word.isalpha() \n",
    "        and word.lower() not in english_words \n",
    "        and word.lower() not in english_names \n",
    "        and word.lower() not in named_entities\n",
    "    ]\n",
    "    \n",
    "    return len(non_english) > 0\n",
    "\n",
    "\n",
    "sample = {'category': 'HISTORY', 'air_date': '2004-12-31', 'question': \"For the last 8 years of his life, was under house arrest for espousing this man's theory'\", 'value': '$200', 'answer': 'Copernicus', 'round': 'Jeopardy!', 'show_number': '4680'}\n",
    "print (contain_non_english(sample['question']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70648df-0ee2-4d0b-b393-cc6f3f9d2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import requests\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def query_wikidata_rarity(noun_tobecheck):\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"language\": \"en\",\n",
    "        \"format\": \"json\",\n",
    "        \"search\": noun_tobecheck,\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    if not data.get(\"search\"):\n",
    "        return True\n",
    "\n",
    "    for result in data[\"search\"]:\n",
    "        description =  result.get(\"description\", \"\").lower()\n",
    "        if any(keyword in description for keyword in [\"person\", \"city\", \"state\", \"country\", \"organization\"]):\n",
    "            return False\n",
    "        if result.get(\"sitelinks\", 0) > 50:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def contain_unusual_proper_nouns(phrase):\n",
    "    doc = nlp(phrase)\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for ent in sent.ents:\n",
    "            if ent.label_ in {\"PERSON\", \"GPE\", \"ORG\", \"LOC\", \"FAC\", \"EVENT\", \"WORK_OF_ART\", \"LAW\"} and query_wikidata_rarity(ent.text):\n",
    "                return True\n",
    "    return False\n",
    "                \n",
    "    '''\n",
    "    PERSON - Person's names, \n",
    "    GPE - Geographic locations, \n",
    "    ORG - Organizations, \n",
    "    LOC - Non-GPE locations, \n",
    "    FAC - Facilities, \n",
    "    EVENT - Named events, \n",
    "    WORK_OF_ART - Titles of books, songs, movies, paintings, \n",
    "    LAW - Named documents made into laws.\n",
    "    '''\n",
    "\n",
    "sample = {'category': 'HISTORY', 'air_date': '2004-12-31', 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\", 'value': '$200', 'answer': 'Copernicus', 'round': 'Jeopardy!', 'show_number': '4680'}\n",
    "\n",
    "print ({contain_unusual_proper_nouns(sample['question'])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bafe2-5296-45c0-a415-db8fab516cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_and_pick(data, filter_func, n=1000):\n",
    "    picked = []\n",
    "    for record in data:\n",
    "        if filter_func(record['question']) or filter_func(record['answer']):\n",
    "            picked.append(record)\n",
    "        if len(picked) >= n:\n",
    "            break\n",
    "    return picked\n",
    "\n",
    "subset_numbers = filter_and_pick(data, contains_numbers, n=1000)\n",
    "subset_non_english = filter_and_pick(data, contain_non_english, n=1000)\n",
    "subset_unusual_proper_nouns = filter_and_pick(data, contain_unusual_proper_nouns, n=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
